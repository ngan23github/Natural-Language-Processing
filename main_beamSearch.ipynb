{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c508c51",
   "metadata": {},
   "source": [
    "## Cài đặt môi trường"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2173cf",
   "metadata": {},
   "source": [
    "### Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "25df0663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5038cd9f",
   "metadata": {},
   "source": [
    "### Cấu hình tham số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "54e3fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "BATCH_SIZE = 64\n",
    "EMBED_DIM = 512\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 2\n",
    "DROPOUT = 0.3\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1.0\n",
    "TEACHER_FORCING_RATIO = 0.5\n",
    "MAX_LEN_DECODING = 50\n",
    "CHECKPOINT_DIR = './checkpoints'\n",
    "os.makedirs(CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "EN_TRAIN = './data/train.en'\n",
    "FR_TRAIN = './data/train.fr'\n",
    "EN_VAL = './data/val.en'\n",
    "FR_VAL = './data/val.fr'\n",
    "EN_TEST = './data/test_2016_flickr.en'\n",
    "FR_TEST = './data/test_2016_flickr.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a09bb11",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "05a71028",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "fr_tokenizer = get_tokenizer('spacy', language='fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14f57ef",
   "metadata": {},
   "source": [
    "### Xây dựng từ điển"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af832272",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(file_path, tokenizer):\n",
    "    with open(file_path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            yield tokenizer(line.strip().lower())\n",
    "\n",
    "def build_vocab(file_path, tokenizer, max_tokens=10000):\n",
    "    vocab = build_vocab_from_iterator(\n",
    "        yield_tokens(file_path, tokenizer),\n",
    "        specials=['<unk>', '<pad>', '<sos>', '<eos>'],\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    vocab.set_default_index(vocab['<unk>'])\n",
    "    return vocab\n",
    "\n",
    "en_vocab = build_vocab(EN_TRAIN, en_tokenizer)\n",
    "fr_vocab = build_vocab(FR_TRAIN, fr_tokenizer)\n",
    "\n",
    "PAD_IDX_EN = en_vocab['<pad>']\n",
    "PAD_IDX_FR = fr_vocab['<pad>']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f644f8f",
   "metadata": {},
   "source": [
    "### Hàm chuyển câu thành chuỗi token ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "60e404ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_sentence(sentence, tokenizer, vocab):\n",
    "    tokens = tokenizer(sentence.strip().lower())\n",
    "    ids = [vocab['<sos>']] + [vocab[token] for token in tokens] + [vocab['<eos>']]\n",
    "    return torch.tensor(ids, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e288010",
   "metadata": {},
   "source": [
    "### Translation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7efb9044",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_file, trg_file, src_tokenizer, trg_tokenizer, src_vocab, trg_vocab):\n",
    "        with open(src_file, encoding='utf-8') as f:\n",
    "            self.src_lines = [l.strip() for l in f.readlines()]\n",
    "        with open(trg_file, encoding='utf-8') as f:\n",
    "            self.trg_lines = [l.strip() for l in f.readlines()]\n",
    "        assert len(self.src_lines) == len(self.trg_lines)\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.trg_tokenizer = trg_tokenizer\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = encode_sentence(self.src_lines[idx], self.src_tokenizer, self.src_vocab)\n",
    "        trg = encode_sentence(self.trg_lines[idx], self.trg_tokenizer, self.trg_vocab)\n",
    "        return src, trg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef32fa9",
   "metadata": {},
   "source": [
    "### Collate fn với Padding & Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a6cb6cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    src_batch, trg_batch = zip(*batch)\n",
    "    src_lengths = torch.tensor([len(s) for s in src_batch], dtype=torch.long)\n",
    "    trg_lengths = torch.tensor([len(t) for t in trg_batch], dtype=torch.long)\n",
    "\n",
    "    sorted_idx = torch.argsort(src_lengths, descending=True)\n",
    "    src_batch = [src_batch[i] for i in sorted_idx]\n",
    "    trg_batch = [trg_batch[i] for i in sorted_idx]\n",
    "    src_lengths = src_lengths[sorted_idx]\n",
    "    trg_lengths = trg_lengths[sorted_idx]\n",
    "\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=PAD_IDX_EN)\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=PAD_IDX_FR)\n",
    "\n",
    "    return src_padded, trg_padded, src_lengths, trg_lengths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6931cc20",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "78b5b043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(src_file, trg_file, batch_size=BATCH_SIZE, shuffle=True):\n",
    "    dataset = TranslationDataset(src_file, trg_file, en_tokenizer, fr_tokenizer, en_vocab, fr_vocab)\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ec9729",
   "metadata": {},
   "source": [
    "## Xây dựng mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d6739d",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cfd6612",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, num_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "\n",
    "    def forward(self, src, src_lengths):\n",
    "        # src: [batch, src_len]\n",
    "        embedded = self.embedding(src)  # [batch, src_len, embed_dim]\n",
    "        packed_emb = pack_padded_sequence(embedded, src_lengths.cpu(), batch_first=True, enforce_sorted=True)\n",
    "        packed_outputs, (hidden, cell) = self.lstm(packed_emb)\n",
    "        outputs, _ = pad_packed_sequence(packed_outputs, batch_first=True, padding_value=0.0)  # [batch, src_len, hidden_dim]\n",
    "        return outputs, hidden, cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a1893b",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3875f8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttention(nn.Module):\n",
    "    def forward(self, decoder_hidden, encoder_outputs, mask=None):\n",
    "        scores = torch.bmm(encoder_outputs, decoder_hidden.unsqueeze(2)).squeeze(2)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(~mask, -1e9)\n",
    "        attn_weights = torch.softmax(scores, dim=1)\n",
    "        context = torch.bmm(attn_weights.unsqueeze(1), encoder_outputs).squeeze(1)\n",
    "        return context, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d75b0b",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fe99b55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hidden_dim, num_layers, dropout, pad_idx):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, embed_dim, padding_idx=pad_idx)\n",
    "        self.lstm = nn.LSTM(embed_dim, hidden_dim, num_layers=num_layers, dropout=dropout, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.attention = LuongAttention()\n",
    "\n",
    "    def forward(self, input_token, hidden, cell, encoder_outputs, src_mask=None):\n",
    "        input_token = input_token.unsqueeze(1)\n",
    "        embedded = self.embedding(input_token)\n",
    "        output, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        dec_hidden = hidden[-1]\n",
    "        context, attn_weights = self.attention(dec_hidden, encoder_outputs, mask=src_mask)\n",
    "        concat = torch.cat([output.squeeze(1), context], dim=1)\n",
    "        prediction = self.fc_out(concat)\n",
    "        return prediction, hidden, cell, attn_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe17648f",
   "metadata": {},
   "source": [
    "### Seq2Seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1f3db8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, teacher_forcing_ratio=TEACHER_FORCING_RATIO):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        self.teacher_forcing_ratio = teacher_forcing_ratio\n",
    "\n",
    "    def forward(self, src, src_lengths, trg=None, teacher_forcing=True):\n",
    "        batch_size = src.size(0)\n",
    "        trg_len = trg.size(1) if trg is not None else MAX_LEN_DECODING\n",
    "        output_dim = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(batch_size, trg_len, output_dim).to(self.device)\n",
    "        encoder_outputs, hidden, cell = self.encoder(src, src_lengths)\n",
    "        src_mask = (src != PAD_IDX_EN).to(self.device)\n",
    "        input_token = trg[:,0] if trg is not None else torch.tensor([fr_vocab['<sos>']]*batch_size, device=self.device)\n",
    "        for t in range(1, trg_len):\n",
    "            teacher_force_flag = (random.random() < self.teacher_forcing_ratio) if (trg is not None and teacher_forcing) else False\n",
    "            output, hidden, cell, _ = self.decoder(input_token, hidden, cell, encoder_outputs, src_mask)\n",
    "            outputs[:, t] = output\n",
    "            top1 = output.argmax(1)\n",
    "            input_token = trg[:,t] if teacher_force_flag and trg is not None else top1\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592e5780",
   "metadata": {},
   "source": [
    "## Huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d755ff",
   "metadata": {},
   "source": [
    "### Hàm huấn luyện 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b0ddb6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, clip, device):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for src, trg, src_lengths, trg_lengths in dataloader:\n",
    "        src, trg, src_lengths = src.to(device), trg.to(device), src_lengths.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, src_lengths, trg, teacher_forcing=True)\n",
    "        output_dim = output.shape[-1]\n",
    "        output_flat = output[:,1:,:].reshape(-1, output_dim)\n",
    "        trg_flat = trg[:,1:].reshape(-1)\n",
    "        loss = criterion(output_flat, trg_flat)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a58c536",
   "metadata": {},
   "source": [
    "### Hàm đánh giá mô hình trên tập validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "98b15323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, criterion, device):\n",
    "    if dataloader is None:\n",
    "        return float('inf')\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for src, trg, src_lengths, trg_lengths in dataloader:\n",
    "            src, trg, src_lengths = src.to(device), trg.to(device), src_lengths.to(device)\n",
    "            output = model(src, src_lengths, trg, teacher_forcing=False)\n",
    "            output_dim = output.shape[-1]\n",
    "            output_flat = output[:,1:,:].reshape(-1, output_dim)\n",
    "            trg_flat = trg[:,1:].reshape(-1)\n",
    "            loss = nn.CrossEntropyLoss(ignore_index=PAD_IDX_FR)(output_flat, trg_flat)\n",
    "            epoch_loss += loss.item()\n",
    "    return epoch_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1affb",
   "metadata": {},
   "source": [
    "### Hàm huấn luyện toàn bộ mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e3a76dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    enc = Encoder(len(en_vocab), EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, PAD_IDX_EN)\n",
    "    dec = Decoder(len(fr_vocab), EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, PAD_IDX_FR)\n",
    "    model = Seq2Seq(enc, dec, DEVICE, TEACHER_FORCING_RATIO).to(DEVICE)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX_FR)\n",
    "\n",
    "    train_loader = get_dataloader(EN_TRAIN, FR_TRAIN, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = get_dataloader(EN_VAL, FR_VAL, batch_size=BATCH_SIZE, shuffle=False) if os.path.exists(EN_VAL) else None\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    patience = 3\n",
    "    wait = 0\n",
    "\n",
    "    # === Thêm biến lưu loss ===\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    logs = []\n",
    "\n",
    "    for epoch in range(1, N_EPOCHS+1):\n",
    "        start = time.time()\n",
    "\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, CLIP, DEVICE)\n",
    "        valid_loss = evaluate(model, val_loader, criterion, DEVICE) if val_loader else train_loss\n",
    "        end = time.time()\n",
    "        duration = end - start\n",
    "\n",
    "        # === Lưu loss mỗi epoch ===\n",
    "        train_losses.append(train_loss)\n",
    "        valid_losses.append(valid_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch} | Train Loss: {train_loss:.4f} | Val Loss: {valid_loss:.4f} | Time: {duration:.1f}s\")\n",
    "\n",
    "        # === Lưu vào bảng log ===\n",
    "        logs.append({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"val_loss\": valid_loss,\n",
    "            \"time_sec\": round(duration, 2)\n",
    "        })\n",
    "\n",
    "        # Save best checkpoint\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'valid_loss': valid_loss\n",
    "            }, os.path.join(CHECKPOINT_DIR, 'best_model.pth'))\n",
    "            wait = 0\n",
    "            print(\"  Saved new best model.\")\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    # ===== In bảng log  =====\n",
    "    print(\"\\n===== Training Logs =====\")\n",
    "    print(f\"{'Epoch':<7} {'Train Loss':<12} {'Val Loss':<12} {'Time (s)':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "\n",
    "    for row in logs:\n",
    "        print(f\"{row['epoch']:<7} {row['train_loss']:<12.4f} {row['val_loss']:<12.4f} {row['time_sec']:<10}\")\n",
    "\n",
    "\n",
    "    # === Vẽ biểu đồ train/val loss ===\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(valid_losses, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Train vs Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig('Loss_curve.png', dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Đã lưu biểu đồ loss.\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34b56c9",
   "metadata": {},
   "source": [
    "## Dự đoán"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dcd1d2",
   "metadata": {},
   "source": [
    "### Greedy Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "033c1ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence: str, model, device, max_len=MAX_LEN_DECODING):\n",
    "    model.eval()\n",
    "    src_tensor = encode_sentence(sentence, en_tokenizer, en_vocab).unsqueeze(0).to(device)\n",
    "    src_lengths = torch.tensor([src_tensor.size(1)], dtype=torch.long).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_lengths)\n",
    "\n",
    "    sos_idx = fr_vocab['<sos>']\n",
    "    eos_idx = fr_vocab['<eos>']\n",
    "    input_token = torch.tensor([sos_idx], dtype=torch.long, device=device)\n",
    "\n",
    "    src_mask = (src_tensor != PAD_IDX_EN).to(device)\n",
    "\n",
    "    output_ids = []\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            pred, hidden, cell, attn = model.decoder(input_token, hidden, cell, encoder_outputs, src_mask)\n",
    "        top1 = pred.argmax(1).item()\n",
    "        if top1 == eos_idx:\n",
    "            break\n",
    "        output_ids.append(top1)\n",
    "        input_token = torch.tensor([top1], dtype=torch.long, device=device)\n",
    "\n",
    "    # detokenize\n",
    "    try:\n",
    "        itos = fr_vocab.get_itos()\n",
    "    except:\n",
    "        itos = [tok for tok, idx in sorted(fr_vocab.get_stoi().items(), key=lambda x: x[1])]\n",
    "    words = [itos[i] for i in output_ids]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820da2b",
   "metadata": {},
   "source": [
    "### Beam Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "189378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_translate(sentence: str, model, device, max_len=MAX_LEN_DECODING, beam_width=3):\n",
    "    model.eval()\n",
    "    src_tensor = encode_sentence(sentence, en_tokenizer, en_vocab).unsqueeze(0).to(device)\n",
    "    src_lengths = torch.tensor([src_tensor.size(1)], device=device)\n",
    "    with torch.no_grad():\n",
    "        encoder_outputs, hidden, cell = model.encoder(src_tensor, src_lengths)\n",
    "\n",
    "    sos_idx, eos_idx = fr_vocab['<sos>'], fr_vocab['<eos>']\n",
    "    src_mask = (src_tensor != PAD_IDX_EN).to(device)\n",
    "\n",
    "    # beam: list of (tokens, hidden, cell, score)\n",
    "    beam = [( [sos_idx], hidden, cell, 0.0 )]\n",
    "    completed = []\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        new_beam = []\n",
    "        for tokens, h, c, score in beam:\n",
    "            if tokens[-1] == eos_idx:\n",
    "                completed.append((tokens, score))  # chỉ lưu tokens + score\n",
    "                continue\n",
    "            input_token = torch.tensor([tokens[-1]], device=device)\n",
    "            with torch.no_grad():\n",
    "                pred, h_new, c_new, _ = model.decoder(input_token, h, c, encoder_outputs, src_mask)\n",
    "                log_probs = F.log_softmax(pred, dim=1)\n",
    "            topk_logp, topk_idx = torch.topk(log_probs, beam_width, dim=1)\n",
    "            for i in range(beam_width):\n",
    "                new_beam.append((tokens+[topk_idx[0,i].item()], h_new, c_new, score+topk_logp[0,i].item()))\n",
    "        beam = sorted(new_beam, key=lambda x: x[3], reverse=True)[:beam_width]\n",
    "        if not beam:\n",
    "            break\n",
    "\n",
    "    # thêm những beam còn lại nếu chưa gặp <eos>\n",
    "    for tokens, h, c, score in beam:\n",
    "        completed.append((tokens, score))\n",
    "\n",
    "    # chọn best\n",
    "    best_tokens, _ = max(completed, key=lambda x: x[1]/len(x[0]))\n",
    "    output_ids = best_tokens[1:]  # bỏ <sos>\n",
    "    if eos_idx in output_ids:\n",
    "        output_ids = output_ids[:output_ids.index(eos_idx)]\n",
    "    words = [fr_vocab.get_itos()[i] for i in output_ids]\n",
    "    return \" \".join(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08b4c98",
   "metadata": {},
   "source": [
    "## Đánh giá BLEU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b50b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bleu(model, src_file, trg_file, device, max_samples=None, use_beam=False, beam_width=3):\n",
    "    smoothie = SmoothingFunction().method4\n",
    "    scores = []\n",
    "    with open(src_file, encoding='utf-8') as fsrc, open(trg_file, encoding='utf-8') as ftrg:\n",
    "        for i, (sline, tline) in enumerate(zip(fsrc, ftrg)):\n",
    "            if max_samples and i >= max_samples:\n",
    "                break\n",
    "            sline = sline.strip()\n",
    "            tline = tline.strip()\n",
    "            if use_beam:\n",
    "                pred = beam_translate(sline, model, device, beam_width=beam_width)\n",
    "            else:\n",
    "                pred = translate(sline, model, device)\n",
    "            reference = [tline.split()]\n",
    "            hypothesis = pred.split()\n",
    "            score = sentence_bleu(reference, hypothesis, smoothing_function=smoothie)\n",
    "            scores.append(score)\n",
    "    return sum(scores)/len(scores) if scores else 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f689084d",
   "metadata": {},
   "source": [
    "## Dịch thử"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05cbe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded best checkpoint.\n",
      "EN: A man in an orange hat starring at something.\n",
      "FR_pred: un homme en une casquette orange regarde quelque chose .\n",
      "------------------------------\n",
      "EN: A Boston Terrier is running on lush green grass in front of a white fence.\n",
      "FR_pred: un terrier terrier terrier court sur l' herbe verte devant une clôture blanche .\n",
      "------------------------------\n",
      "EN: A girl in karate uniform breaking a stick with a front kick.\n",
      "FR_pred: une fille en tenue de karaté frappant un coup avec un bâton de pied .\n",
      "------------------------------\n",
      "EN: Five people wearing winter jackets and helmets stand in the snow, with snowmobiles in the background.\n",
      "FR_pred: cinq personnes portant des manteaux d' hiver et des casques sont debout dans la neige , avec des voiliers en arrière-plan .\n",
      "------------------------------\n",
      "EN: People are fixing the roof of a house.\n",
      "FR_pred: des gens réparent le toit d' une maison .\n",
      "------------------------------\n",
      "BLEU on test: 0.26460954539669834\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = run_training()\n",
    "    ckpt_path = os.path.join(CHECKPOINT_DIR, 'best_model.pth')\n",
    "    if os.path.exists(ckpt_path):\n",
    "        data = torch.load(ckpt_path, map_location=DEVICE)\n",
    "        enc = Encoder(len(en_vocab), EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, PAD_IDX_EN)\n",
    "        dec = Decoder(len(fr_vocab), EMBED_DIM, HIDDEN_DIM, NUM_LAYERS, DROPOUT, PAD_IDX_FR)\n",
    "        model = Seq2Seq(enc, dec, DEVICE).to(DEVICE)\n",
    "        model.load_state_dict(data['model_state_dict'])\n",
    "        print(\"Loaded best checkpoint.\")\n",
    "\n",
    "    TEST_FILE = './data/test_2016_flickr.en'\n",
    "    with open(TEST_FILE, encoding='utf-8') as f:\n",
    "        for i in range(5):\n",
    "            s = f.readline().strip()\n",
    "            print(\"EN:\", s)\n",
    "            print(\"FR_pred:\", beam_translate(s, model, DEVICE, beam_width=3))\n",
    "            print(\"-\"*30)\n",
    "\n",
    "    if os.path.exists(EN_TEST) and os.path.exists(FR_TEST):\n",
    "        bleu = compute_bleu(model, EN_TEST, FR_TEST, DEVICE, max_samples=200, use_beam=True, beam_width=3)\n",
    "        print(\"BLEU on test:\", bleu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
